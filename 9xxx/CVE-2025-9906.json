{
  "cveMetadata": {
    "cveId": "CVE-2025-9906",
    "assignerOrgId": "14ed7db2-1595-443d-9d34-6215bf890778",
    "state": "PUBLISHED",
    "assignerShortName": "Google",
    "dateReserved": "2025-09-03T07:27:23.895Z",
    "datePublished": "2025-09-19T08:15:04.349Z",
    "dateUpdated": "2025-09-20T03:55:41.698Z"
  },
  "containers": {
    "cna": {
      "affected": [
        {
          "defaultStatus": "unaffected",
          "product": "Keras",
          "repo": "https://github.com/keras-team/keras",
          "vendor": "Keras-team",
          "versions": [
            {
              "lessThan": "3.11.0",
              "status": "affected",
              "version": "3.0.0",
              "versionType": "semver"
            }
          ]
        }
      ],
      "credits": [
        {
          "lang": "en",
          "type": "finder",
          "value": "Gabriele Digregorio"
        }
      ],
      "datePublic": "2025-06-29T09:00:00.000Z",
      "descriptions": [
        {
          "lang": "en",
          "supportingMedia": [
            {
              "base64": false,
              "type": "text/html",
              "value": "<p>The Keras <code>Model.load_model</code>&nbsp;method can be exploited to achieve arbitrary code execution, even with <code>safe_mode=True</code>.</p><p>One can create a specially crafted <code>.keras</code>&nbsp;model archive that, when loaded via <code>Model.load_model</code>, will trigger arbitrary code to be executed. This is achieved by crafting a special <code>config.json</code>&nbsp;(a file within the <code>.keras</code>&nbsp;archive) that will invoke <code>keras.config.enable_unsafe_deserialization()</code>&nbsp;to disable safe mode. Once safe mode is disable, one can use the <code>Lambda</code>&nbsp;layer feature of keras, which allows arbitrary Python code in the form of pickled code. Both can appear in the same archive. Simply the <code>keras.config.enable_unsafe_deserialization()</code>&nbsp;needs to appear first in the archive and the <code>Lambda</code>&nbsp;with arbitrary code needs to be second.</p><br>"
            }
          ],
          "value": "The Keras Model.load_model method can be exploited to achieve arbitrary code execution, even with safe_mode=True.\n\nOne can create a specially crafted .keras model archive that, when loaded via Model.load_model, will trigger arbitrary code to be executed. This is achieved by crafting a special config.json (a file within the .keras archive) that will invoke keras.config.enable_unsafe_deserialization() to disable safe mode. Once safe mode is disable, one can use the Lambda layer feature of keras, which allows arbitrary Python code in the form of pickled code. Both can appear in the same archive. Simply the keras.config.enable_unsafe_deserialization() needs to appear first in the archive and the Lambda with arbitrary code needs to be second."
        }
      ],
      "impacts": [
        {
          "capecId": "CAPEC-242",
          "descriptions": [
            {
              "lang": "en",
              "value": "CAPEC-242 Code Injection"
            }
          ]
        }
      ],
      "metrics": [
        {
          "cvssV4_0": {
            "Automatable": "YES",
            "Recovery": "AUTOMATIC",
            "Safety": "NOT_DEFINED",
            "attackComplexity": "LOW",
            "attackRequirements": "NONE",
            "attackVector": "LOCAL",
            "baseScore": 8.6,
            "baseSeverity": "HIGH",
            "privilegesRequired": "LOW",
            "providerUrgency": "NOT_DEFINED",
            "subAvailabilityImpact": "HIGH",
            "subConfidentialityImpact": "HIGH",
            "subIntegrityImpact": "HIGH",
            "userInteraction": "PASSIVE",
            "valueDensity": "NOT_DEFINED",
            "vectorString": "CVSS:4.0/AV:L/AC:L/AT:N/PR:L/UI:P/VC:H/VI:H/VA:H/SC:H/SI:H/SA:H/AU:Y/R:A",
            "version": "4.0",
            "vulnAvailabilityImpact": "HIGH",
            "vulnConfidentialityImpact": "HIGH",
            "vulnIntegrityImpact": "HIGH",
            "vulnerabilityResponseEffort": "NOT_DEFINED"
          },
          "format": "CVSS",
          "scenarios": [
            {
              "lang": "en",
              "value": "GENERAL"
            }
          ]
        }
      ],
      "problemTypes": [
        {
          "descriptions": [
            {
              "cweId": "CWE-502",
              "description": "CWE-502 Deserialization of Untrusted Data",
              "lang": "en",
              "type": "CWE"
            }
          ]
        }
      ],
      "providerMetadata": {
        "orgId": "14ed7db2-1595-443d-9d34-6215bf890778",
        "shortName": "Google",
        "dateUpdated": "2025-09-19T08:15:04.349Z"
      },
      "references": [
        {
          "tags": [
            "patch"
          ],
          "url": "https://github.com/keras-team/keras/pull/21429"
        }
      ],
      "source": {
        "discovery": "EXTERNAL"
      },
      "title": "Arbitrary Code execution in Keras Safe Mode"
    },
    "adp": [
      {
        "metrics": [
          {
            "other": {
              "type": "ssvc",
              "content": {
                "timestamp": "2025-09-19T00:00:00+00:00",
                "options": [
                  {
                    "Exploitation": "none"
                  },
                  {
                    "Automatable": "no"
                  },
                  {
                    "Technical Impact": "total"
                  }
                ],
                "role": "CISA Coordinator",
                "version": "2.0.3",
                "id": "CVE-2025-9906"
              }
            }
          }
        ],
        "title": "CISA ADP Vulnrichment",
        "providerMetadata": {
          "orgId": "134c704f-9b21-4f2e-91b3-4a467353bcc0",
          "shortName": "CISA-ADP",
          "dateUpdated": "2025-09-20T03:55:41.698Z"
        }
      }
    ]
  },
  "search": "解析验收测试文案"
}